

\section{Introduction}


We end up this thesis by summarising results and suggesting a few challenges.
After several waves of popularity, NN models seem to 
have reached a definitive momentum because of the many relevant applications
based on them. Most work in NNs is based on the MLE tradition.
We have highlighted and illustrated the benefits of a Bayesian treatment of deep learning. Indeed, as we have described,
they provide improved uncertainty estimates;
they have enhanced generalization capabilities; 
they have more robustness against adversarial attacks.
We also note that, although not studied in this thesis, 
they have improved capabilities for model calibration;
and the use of sparsity-inducing priors, could further induce 
improvements in learning. 
However, efficient Bayesian integration methods in 
deep NN are 
still to be found, this remaining a major challenge.
In particular their solution would facilitate the
development of probabilistic programming \parencite{gordon2014probabilistic,carpenter2017stan,wood2014new}
as the next step for differentiable programming,
leading to new tools for the 21st century Bayesian 
statistics.


\section{Large Scale Bayesian Inference}\label{sec:conclusion_lsb}

\subsection{Summary}

This chapter has shown how to generate new SG-MCMC methods, such as SGLD+R and Adam+NR, consisting of multiple chains plus repulsion between the particles. Instead of a naive parallelization, in which a particle from a chain is agnostic to the others, we showed how it is possible to adapt another method from the literature, SVGD, to account for a better exploration of the space, avoiding collapse between particles. We also showed how momentum-accelerated extensions of SGD can be used as SG-MCMC samplers, while also being compatible with the extension to repulsive forces between parallel chains. Our 
experiments show that the proposed ideas improve efficiency when dealing 
with large scale inference and prediction problems in presence of many 
parameters and large data sets.

In the second part, we have proposed a flexible and efficient framework to perform
large-scale Bayesian inference in probabilistic models. The scheme benefits from useful properties and can be 
employed to efficiently perform inference with a wide class of models such as state-space time series, variational autoencoders {and variants such as the conditioned VAE for classification tasks}, defined through continuous, high-dimensional distributions.

The framework can be seen as a general 
approach to tuning MCMC sampler parameters, adapting the initial distributions and learning rate. %We believe the proposed scheme can be successfully applied to Adversarial Risk Analysis \parencite{rios2009adversarial}, since MAIDs \parencite{koller2003multi} are considered in that setting and it is customary to account for additional uncertainty over an attacker's influence diagram. Our framework paves the way for flexible inference and decision making under uncertainty in these settings, and we will explore this in future work.
Key to the success and applicability of the VIS framework are the ELBO approximations based on the introduced refined variational approximation, which are computationally cheap but convenient. 

\subsection{Further work}

Several avenues are open for further work. Here we discuss only several promising ones. First, with a very large particle regime ($L >> 100$) there is room to use approximating algorithms such as Barnes-Hutt to keep the computational cost tractable.
Secondly, we used the RBF kernel in all our experiments, but a natural 
issue to address would be to define a parameterized kernel $k_{\theta} (z_i, z_j)$ and learn the parameters $\theta$ on the go to optimize the ESS/s rate, using meta-learning approaches such as the one proposed in \parencite{gallego2019vis} for the SGLD case.
When dealing with shallow networks in comparatively small scale problems
\parencite{Muller} dealing with acceptance Metropolis steps was crucial, for example,
when focusing on architecture selection; incorporating such steps
to the proposed approaches could be beneficial. 
If many more particles are  used, one could approximate the expectation in (\ref{eq:svgd_mat}) using subsampling at each iteration, as proposed by the authors of SVGD, or by using more sophisticated approaches from the molecular dynamics literature, such as the Barnes-Hutt algorithm, \parencite{barnes1986hierarchical}, to arrive at an efficient $\mathcal{O}(L \log L)$ computational burden at a negligible approximation error.

Better estimates of the refined density and its gradient may be a fruitful line of research, such as the spectral estimator used in \parencite{shi2018spectral}. Another alternative is to use a deterministic flow (such as SGD or SVGD), keeping
track of the change in entropy at each iteration using the change of the variable formula, as in \parencite{duvenaud2016early}. However, this requires a costly Jacobian computation, making it unfeasible to combine with our approach of back-propagation through the sampler (Section \ref{sec:tuning}) for moderately complex problems. We leave this for future exploration. {Another interesting and useful line of further research would be to tackle the case in which the latent variables $z$ are discrete. This would entail adapting the automatic differentiation techniques to be able to back-propagate the gradients through the sequences of acceptance steps necessary in Metropolis--Hastings samplers.}

In order to deal with the implicit variational density, it may be worthwhile to consider optimizing the Fenchel dual of the KL divergence, as
 in \parencite{fang2019implicit}. However, this requires the use of an auxiliary neural network, which may entail a large computational price compared with our simpler particle approximation.

Lastly, probabilistic programming offers powerful tools for Bayesian modeling.
A~PPL can be viewed as a programming language extended with random sampling and Bayesian conditioning capabilities, complemented with an inference engine that produces answers to inference, prediction and decision-making queries. Examples 
include WinBUGS~\parencite{lunn2000winbugs}, Stan \parencite{carpenter2017stan} or the recent Edward \parencite{tran2018simple} and Pyro \parencite{bingham2018pyro} languages. We plan to adapt VIS into several PPLs to facilitate the adoption of the framework.


\section{Adversarial Classification}

\subsection{Summary}

Adversarial classification aims at enhancing classifiers to achieve robustness in presence of adversarial examples, as usually encountered in many security applications. The pioneering work of \parencite{adversarialClassification2004} framed most later approaches to AC 
within the standard game theoretic paradigm, in spite of the unrealistic common knowledge assumptions about shared beliefs and preferences required, actually even questioned by those authors. After reviewing them, and analysing  their assumptions, we have presented two formal probabilistic approaches for AC based on ARA that mitigate 
such strong common knowledge assumptions.
They are general in the sense that application-specific assumptions are kept to a minimum. 
%
We have presented the framework in two different forms: in Section \ref{sec:ac_acra}, learning about the adversary is performed in the
operational phase, for generative classifiers. In Section \ref{sec:scalable}, adversarial aspects are incorporated in the training phase. Depending on the particular application, one of the frameworks could be preferred over the other. The first one allows us to make real time inference about the adversary, as it explicitly models his decision making process in operation time; its adaptability is better as it does not need to be retrained every time we need to modify the adversary model. However, this comes at a high computational cost, and the harsh restriction of being only applicable to generative models. In applications in which there is a computational bottleneck, the second approach may be preferable, with possible changes in the adversary's behaviour incorporated via retraining.
This tension between the need to robustify algorithms against attacks (training phase, Section  \ref{sec:scalable}) and the fast adaptivity of attackers against defences (operational phase, Section \ref{sec:ac_acra}) is well exemplified in the phishing detection domain as discussed in \parencite{rakesh}.


% We have presented variants of ACRA to deal with both generative and discriminative classifiers, and also an extension of it suitable for computationally demanding problems.





%Also, we have provided empirical evidence supporting the robustness of the ACRA framework to imprecisions in the assumptions made about the adversary. In particular, ACRA has been shown to be more robust than its common knowledge, purely game theoretic counterpart. Finally, we have presented computational enhancements that have significantly improved ACRA performance, allowing us to solve large problems and use it in operational settings.
\subsection{Further work}

Our framework may be extended in several ways. First, we could adapt the proposed approach to situations in which there is repeated play of the AC game, introducing the possibility of learning the adversarial utilities and probabilities in a Bayesian way. Learning over opponent types has been explored with success in reinforcement learning scenarios, \parencite{gallego2019opponent}. This could be extended to the classification setting. Besides exploratory ones, attacks over the training data \parencite{biggio2012poisoning} may be relevant in certain contexts. 
%In addition, we have just considered the case in which the attacker performs intentional attacks. % In some problems, there could be also random attacks. The proposed framework could be easily adapted to take those into account as well as to the case in which there are several attackers. 
In addition, the extension to the case of attacks to innocent instances (not just integrity violation ones) seems feasible using the scalable framework. % but requires some work in our original one.
We have restricted our attention to deterministic attacks, that is, $a^*(x,y_1)$ will always lead to $x'$; extending our framework to deal with stochastic attacks would entail modelling $p(x' \vert a^*, x, y_1)$. 
%Through this paper, we focused on the binary classification task. An initial extension to multi-class problems is shown in \parencite{gallego2020protecting}, but further attention to this setting would be helpful.

% First of all, in our examples we have used NB as the basic classifier in the preprocessing phase. We could use other generative classifiers, such as variational autoencoders, or even a mixture of them. It would be very interesting to extend the framework to use it with discriminative classifiers, specifically based on neural networks.


%Finally, our work could be extended to the case of attacks to innocent instances (not just integrity violation ones). In this case, when computing $p_C(x'|-)$ in \eqref{pis} we must proceed similarly as we did when computing $p_C(x'|+)$: we consider all possible originating instances $x$ leading to $x'$, and sum them weighting each of them with their $p_C(a_{x \rightarrow x'}| x, -)$, the probability of the attacker choosing the attack linking each of them with $x'$, given that they are innocent. This would just involve replacing $p_C(x'|-)$ by $\sum_{x \in \mathcal{X}'} p_C(a_{x \rightarrow x'}| x, -)p_C(x|-)$ in \eqref{pis}. Finally, as computing both $p_C(a_{x \rightarrow x'}| x, -)$ and $p_C(a_{x \rightarrow x'}| x, +)$ demands strategic thinking, we need to consider the attacker's problem as we did in Section \ref{subsec:theAdversaryProblem}, but this time allowing the attacker to modify also innocent instances.

%We have concentrated on binary classification problems, but the extension to multi-label classification is relevant. This would entail including the summands corresponding to each class in $\eqref{pis}$ and building an appropriate attacker model depending on his particular interests: for instance, he could be interested on making the classifier mislabel any instance or in making her classify instances within a particular group of classes. It is clear that the presence of an adversary would invalidate the one-vs-one and one-vs-rest approaches to multiclass classification, as this procedure could be easily exploited. This would affect the choice of the base classifier within the ACRA approach.


%We have illustrated the approach in a spam detection task, but other areas like malware or fraud detection, or image classification are truly important.
Additional work should be undertaken concerning the
algorithmic aspects.  In our approach  we go through a simulation stage to forecast attacks and an optimisation stage to determine optimal classification. The whole process might be performed through a single stage, possibly based on augmented probability simulation \parencite{ekin2019augmented}.

We have also shown how the robustification procedure from Section \ref{sec:scalable} can be an efficient way to protect large-scale models, such as those trained using first-order methods. It is well-known that Bayesian marginalisation improves generalisation capabilities of flexible models since the ensemble helps in better exploring the posterior parameter space \parencite{wilson2020bayesian}. Our experiments suggest 
that this holds also in the domain of adversarial robustness. Thus, bridging the gap between large scale Bayesian methods and Game Theory, as  done in the ARA framework, suggests a powerful way to develop principled defences. To this end, strategies to more efficiently explore the highly complex, multimodal posterior distributions of neural models constitute another line of further work.

Lastly, several application areas could benefit highly from
protecting their underlying ML models. Spam detectors have been
the running example in this article. Malware and phishing detection are two
crucial cybersecurity problems in which the data distribution of computer programs is constantly changing, driven by attacker's interests in evading detectors. Finally, the machine learning algorithms underlying 
autonomous driving systems need to be robustified from perturbations to their visual processing models and this could be performed through our 
approaches.



\section{Adversarial aspects in Reinforcement Learning}\label{sec:final}
%\section{CONCLUSIONS AND FURTHER WORK}

%\subsection{A discussion for TMDPs}
\subsection{Summary}

We have introduced TMDPs, a reformulation of MDPs to 
 support decision makers who confront opponents that interfere 
with the reward generating process in RL settings.
They have potential applications in security, cybersecurity and 
competitive marketing, to name but a few.
TMDPs aim at providing one-sided prescriptive support to a RL agent, maximizing her expected utility, taking into account potential negative actions adopted by an adversary. % Some theoretical results have been provided. In particular, we prove that
  The proposed learning rule is a contraction mapping and we may use RL convergence results, while gaining advantage from 
%In addition, the proposed framework is suitable for
  opponent modelling within $Q$-learning. Indeed, we have proposed a scheme to model adversarial behavior based on level-$k$ reasoning
and extended it by using type-based reasoning to account for uncertainty about the opponent's level. Finally, we have sketched how the framework could be extended to deep learning settings and to the multiple opponents case. Key features of our proposal are its generality
(it is model agnostic as it is compatible with tabular $Q$-learning or any function approximator for the $Q$-values) and its robustness, since it also offers 
protection against adversarial behaviours that are not exactly as described by the DM's opponent model. These significant benefits come at a reasonable cost, since the increase in complexity (both in time and space) is linear compared to unprotected, baseline vanilla $Q$-learners.

Empirical evidence is provided via extensive experiments, with encouraging results. In security settings, we see that by explicitly modelling a finite set of adversaries via the opponent averaging scheme, a supported DM can take advantage of her actual opponent, even when he is not explicitly modelled through a component from the finite mixture. This highlights the ability of our framework to generalize between different kinds of opponents. As a take home lesson, we find that a level-2 $Q$-learner may effectively deal with a wide class of adversaries. However, maintaining a mixture of different adversaries is necessary if we consider a level-3 DM. As a rule of thumb, the supported DM may start at a low level in the hierarchy, and switch to a level-up temporarily, to check if the obtained rewards are higher. Otherwise, she would  continue on the initial, lower level.  %In addition, the
%proposed Algorithm \ref{alg:l2ur} can be generalized to account for the use of function approximators instead of tabular $Q$-learning, as done in the experiments in Section \ref{sec:cg}. We have also shown details of the modified algorithm in this last batch of experiments. 
Indeed, the proposed scheme is
model agnostic, so we expect it to be usable in both shallow and deep multi-agent RL settings, such as the ones pioneered by \parencite{mnih2015human}. This is a desirable key property of our framework, which implies that it can be adopted in a wide array of relevant settings and configurations.









%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{A discussion for data sharing games}

Regarding the data sharing games, it can be useful to recall that a defining trend in modern society is the abundance 
of data which opens up new opportunities, challenges
and threats. In the upcoming years, social progress will be essentially conditioned by the capacity of society to gather, analyze and understand data, as this will 
facilitate better and more informed decisions. 
Thus, to guarantee social progress,  efficient mechanisms
for data sharing are key. Obviously, such mechanisms
should not only facilitate the data sharing process, 
but must also guarantee the protection of the citizen's personal
information. As a consequence, the problem of data sharing not only
has importance from a socioeconomic perspective, but also from the
legislative point of view. This is well described in numerous recent legislative pieces from the 
EU, e.g.\ \parencite{europe1}, as well as in the concept of flourishing 
in a data-enabled society \parencite{allea}. 

%is of paramount importance in current socioeconomic and legislative issues. 

We have studied the problem of data sharing
from a dynamic game theoretic perspective with two agents.
%. Two agents intervene in the data sharing game: the dominant data owner and the data providers (citizens). Each agent can either cooperate or defect. In the DDO's case, cooperation entails purchasing just the citizen's data that might be purchased and respecting her personal information; while defection entails not paying for the citizen's data. On the  other hand, the citizen will cooperate if she sells data and demands protection, and she will defect when selling wrong/noisy data. 
Within our setting,  mutual cooperation emerges as the strategy 
leading to the best social outcome, and it must be promoted somehow. We
have proposed modelling the confrontation between dominant data owners and citizens using two versions of the iterated prisoner dilemma via  
multi agent reinforcement learning: the decentralized case, in which both agents interact freely, and the centralized case, in which the interaction is regulated by an external agent/institution. In the first case, we have shown that there are strategies with which mutual cooperation is possible, and that a forgiving policy by the DDO can be beneficial in terms of social utility. In the centralized case, regulating the interaction between citizens and DDOs via an external agent could foster mutual cooperation through taxes and incentives.

 Besides fostering cooperation,  the data sharing game may be seen as
  an instance of a two sided market \parencite{rochet2006two}. Therefore,
  the creation of intermediary platforms that facilitate the connection between dominant data owners and citizens to enable data sharing
  would be key to guarantee social progress. 
  

\subsection{Further work}

Several lines of work are possible for further research. First of all, in the experiments, we have just considered DMs up to level-3,
though the extension to higher order adversaries is relevant. %In recent years $Q$-learning has benefited from advances from the deep learning community, with breakthroughs such as the
%\emph{deep $Q$-network} (DQN) which achieved super-human performance in control
%tasks such as the Atari games \parencite{mnih2015human}, or as inner blocks inside
%systems that play Go \parencite{silver2017mastering}. Integrating these advances into
%the TMDP setting is another possible research path.as presented here. 
In addition, rather than trying to learn opponent $Q$-values, we could
use policy gradient methods \parencite{baxter2000direct} to expand our proposal.
It also might be interesting to explore similar expansions to semi-MDPs, 
in order to perform hierarchical RL or allow for time-dependent rewards 
and transitions between states.